
# Enterprise Ingestion Demo

This project simulates an enterprise-grade ingestion pipeline from SharePoint exports to Redshift (mocked via PostgreSQL), transforming the data with dbt, and orchestrated via GitHub Actions.

## ğŸ’¡ Project Purpose

To showcase engineering capabilities in:
- Config-driven ingestion with Python
- Schema validation and error handling
- dbt semantic modeling (staging â†’ marts)
- CI/CD automation using GitHub Actions
- Modular, scalable data platform design

## ğŸ”§ Stack

- Python (pandas, openpyxl, pyyaml)
- dbt-core
- PostgreSQL (mock Redshift)
- GitHub Actions
- YAML (for config)
- pytest (validation)
- Power BI (optional downstream use)

## ğŸ“‚ Structure

```
enterprise_ingestion_demo/
â”œâ”€â”€ data/                 â† Mock Excel data from "SharePoint"
â”œâ”€â”€ ingestion/            â† Python scripts to load and validate
â”œâ”€â”€ dbt_project/          â† dbt models
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ staging/
â”‚       â”œâ”€â”€ intermediate/
â”‚       â””â”€â”€ marts/
â”œâ”€â”€ tests/                â† Pytest schema tests
â”œâ”€â”€ .github/workflows/    â† CI/CD YAML
â””â”€â”€ README.md             â† You're reading it
```

## âœ… Goals

- Show modular data engineering thinking
- Demonstrate practical dbt usage
- Make engineering ability visible for hiring manager

## ğŸš€ Next Steps

1. Generate mock Excel files in `/data`
2. Write `ingestion/main.py` to parse config and upload to Postgres
3. Define `config.yml` for source definitions
4. Create dbt project, models, and tests
5. Push with GitHub Actions to validate CI pipeline
